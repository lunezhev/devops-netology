> # Домашнее задание к занятию «Микросервисы: подходы»

# Q/A

> Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры. Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: Обеспечить разработку

> Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

> Решение должно соответствовать следующим требованиям:
> 
> * облачная система;
> * система контроля версий Git;
> * репозиторий на каждый сервис;
> * запуск сборки по событию из системы контроля версий;
> * запуск сборки по кнопке с указанием параметров;
> * возможность привязать настройки к каждой сборке;
> * возможность создания шаблонов для различных конфигураций сборок;
> * возможность безопасного хранения секретных данных (пароли, ключи доступа);
> * несколько конфигураций для сборки из одного репозитория;
> * кастомные шаги при сборке;
> * собственные докер-образы для сборки проектов;
> * возможность развернуть агентов сборки на собственных серверах;
> * возможность параллельного запуска нескольких сборок;
> * возможность параллельного запуска тестов.
> 
> Обоснуйте свой выбор.
> 
> ---

### Ответ:

Для обеспечения процесса разработки, хранения исходного кода, непрерывной интеграции и непрерывной поставки в облачной системе на основе Git, мне приходилось использовать следующее решение:

* Система контроля версий: GitLab

GitLab предоставляет широкий спектр функциональности для управления Git-репозиториями и включает в себя инструменты для непрерывной интеграции и непрерывной поставки.

* Облачная инфраструктура: AWS (Amazon Web Services)

AWS предлагает гибкость, масштабируемость и широкий набор сервисов, таких как Elastic Compute Cloud (EC2) для развертывания серверов, Elastic Container Registry (ECR) для хранения Docker-образов и Simple Storage Service (S3) для хранения артефактов сборки и других файлов.

* Непрерывная интеграция и непрерывная поставка: GitLab CI/CD

GitLab CI/CD позволяет определить пайплайны сборки и развертывания, которые автоматически запускаются при изменениях в репозитории.
Возможность запуска сборки по событию из системы контроля версий и по кнопке с указанием параметров удовлетворяет требованиям.
Настройки для каждой сборки могут быть заданы в виде файлов конфигурации, которые хранятся в репозитории. Это позволяет привязать настройки к каждой сборке и создавать шаблоны для различных конфигураций сборок.

* Безопасное хранение секретных данных: GitLab CI/CD Variables и AWS Secrets Manager

GitLab CI/CD позволяет определять переменные окружения, которые можно использовать в процессе сборки. Секретные данные, такие как пароли или ключи доступа, могут быть сохранены как переменные окружения в GitLab CI/CD Variables с защитой от неавторизованного доступа.
Для хранения секретных данных в AWS, можно воспользоваться сервисом AWS Secrets Manager, который обеспечивает безопасное хранение и управление секретами.

* Параллельный запуск сборок и тестов: GitLab Runner и Docker

GitLab Runner позволяет запускать агентов сборки на собственных серверах, что обеспечивает возможность параллельного запуска нескольких сборок и выполнения тестов.
Использование Docker-образов для сборки проектов позволяет легко управлять зависимостями и обеспечивает повторяемость и изолированность среды выполнения.

Данное решение на основе GitLab, AWS и Docker удовлетворяет всем предложенным требованиям. Оно предоставляет интегрированную среду для хранения исходного кода, выполняет непрерывную интеграцию и непрерывную поставку, обеспечивает безопасное хранение секретных данных и поддерживает параллельный запуск нескольких сборок и тестов. Кроме того, выбранные инструменты широко используются в индустрии, обладают обширной документацией и развитым комьюнити.

## Задача 2: Логи

> Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

> Решение должно соответствовать следующим требованиям:
> 
> сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
> минимальные требования к приложениям, сбор логов из stdout;
> гарантированная доставка логов до центрального хранилища;
> обеспечение поиска и фильтрации по записям логов;
> обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
> возможность дать ссылку на сохранённый поиск по записям логов.
> 
> Обоснуйте свой выбор.
> 
> ---

### Ответ:

Для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре, я использую следующее решение:

* Централизованное хранилище логов: Elasticsearch и Kibana (ELK stack)

Elasticsearch предоставляет распределенное хранилище данных, которое может эффективно обрабатывать и индексировать большие объемы логов.
Kibana является визуализационным интерфейсом для Elasticsearch и позволяет выполнять поиск, фильтрацию и анализ логов с помощью гибких запросов и дашбордов.

* Сбор логов: Filebeat

Filebeat является легким агентом, который устанавливается на каждом хосте для чтения и передачи лог-файлов в централизованное хранилище.
Filebeat также поддерживает сбор логов из stdout приложений без необходимости внесения изменений в код.

* Гарантированная доставка логов: Logstash

Logstash обеспечивает обработку и трансформацию лог-событий перед их передачей в Elasticsearch.
Logstash имеет механизмы обработки ошибок и повторной отправки логов в случае проблем с доставкой.

* Аутентификация и авторизация: X-Pack Security

Для обеспечения безопасности доступа к логам предлагается использовать модуль X-Pack Security, который предоставляет механизмы аутентификации и авторизации пользователей.
Разработчики могут получить доступ к пользовательскому интерфейсу Kibana для поиска по записям логов, предоставив им соответствующие разрешения.
Сохранение запросов и ссылки на поиск: Kibana Saved Searches и Dashboards

Kibana позволяет сохранять поисковые запросы и создавать дашборды для отображения важных метрик и графиков.
Созданные поисковые запросы могут быть сохранены, что позволяет создавать ссылки на сохраненные поиски и делиться ими с разработчиками.

Выбранное решение основано на ELK stack (Elasticsearch, Logstash, Kibana), которое широко используется в индустрии для централизованного сбора и анализа логов. Elasticsearch обеспечивает эффективное хранение и поиск логов, Filebeat обеспечивает сбор лог-файлов с хостов, Logstash обрабатывает и трансформирует логи, а Kibana предоставляет пользовательский интерфейс для поиска и визуализации логов.

Это решение соответствует всем предложенным требованиям, так как обеспечивает сбор логов со всех хостов, обслуживающих систему, минимальные требования к приложениям для сбора логов из stdout, гарантированную доставку логов до центрального хранилища, возможность поиска и фильтрации записей логов, пользовательский интерфейс для разработчиков и возможность сохранять ссылки на поиск.

## Задача 3: Мониторинг

> Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

> Решение должно соответствовать следующим требованиям:
> 
> * сбор метрик со всех хостов, обслуживающих систему;
> * сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
> * сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
> * сбор метрик, специфичных для каждого сервиса;
> * пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
> * пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.
> 
> Обоснуйте свой выбор.
> 
>---

### Ответ:

Для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре, я использую следующее решение:

* Сбор метрик: Prometheus и Grafana

Prometheus - система мониторинга и сбора метрик, способная собирать данные о состоянии хостов и сервисов.
Grafana - платформа для визуализации и анализа данных, которая интегрируется с Prometheus и позволяет создавать пользовательские дашборды для отслеживания состояния системы.

* Экспортеры: Node Exporter и Service-specific Exporters

Node Exporter собирает метрики о состоянии ресурсов хостов, таких как CPU, RAM, HDD и Network.
Service-specific Exporters позволяют собирать метрики, специфичные для каждого сервиса, например, число запросов в секунду или время выполнения операций.

* Мониторинг состояния сервисов: Health Checks

Для мониторинга состояния сервисов можно использовать Health Checks, которые периодически проверяют доступность и работоспособность сервисов. Результаты проверок могут быть экспортированы в Prometheus.

* Визуализация и анализ: Grafana

Grafana предоставляет гибкие возможности для визуализации собранных метрик, создания дашбордов и настройки панелей для отслеживания состояния системы. Он также позволяет делать запросы к данным и агрегировать информацию.

Выбранное решение основано на Prometheus и Grafana, которые являются широко используемыми инструментами для мониторинга и визуализации данных. Prometheus обеспечивает сбор метрик со всех хостов и сервисов, а Grafana предоставляет пользовательский интерфейс для визуализации и анализа этих метрик.

Это решение соответствует всем предложенным требованиям, так как обеспечивает сбор метрик со всех хостов и сервисов, включая метрики состояния ресурсов хостов и потребляемых ресурсов для каждого сервиса. Пользователи могут использовать интерфейс Grafana для создания запросов и агрегирования информации, а также настраивать различные панели для отслеживания состояния системы.